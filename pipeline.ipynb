{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iniciando o projeto com as importa√ß√£o das dependencias\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FASE 1 - CONFIGURA√á√ÉO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports do projeto\n",
    "\n",
    "import pandas as pd\n",
    "import gdown as gd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONSTANTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constanttes\n",
    "SOURCE_FOLDER = 'source'\n",
    "DF_FILE_NAME = 'df_fraud_credit'\n",
    "PARQUET = 'parquet'\n",
    "CSV = 'csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUN√á√ïES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fun√ß√£o que criar os relat√≥rios de Qualidade de Dados\n",
    "\n",
    "def montar_estatisticas_dataFrame(originial, tratado):\n",
    "    total_registros = len(originial)\n",
    "    total_tratado = len(tratado)\n",
    "    dados_invalidos = total_registros - total_tratado\n",
    "    dados_validos = total_registros - dados_invalidos\n",
    "    percentual_erro = dados_invalidos / total_registros\n",
    "\n",
    "    # Exibir as m√©tricas\n",
    "    print(\"\\nüìå **Data Quality Report**\\n\")\n",
    "    print(f\"üìä Total de registros importados: {total_registros}\")\n",
    "    print(f\"‚úÖ Registros v√°lidos: {dados_validos}\")\n",
    "    print(f\"‚ùå Registros com erro: {dados_invalidos}\")\n",
    "    print(f\"% Registros com erro: {percentual_erro:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fun√ß√£o para cria√ß√£o de pasta\n",
    "\n",
    "def criar_pasta(folderName):\n",
    "    os.makedirs(folderName, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fun√ß√£o para montar a string do caminho do arquivo\n",
    "def makeFolderName(folder, fileName, fileFormat):\n",
    "    return \"./{}/{}.{}\".format(folder, fileName, fileFormat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fun√ß√£o que checa se o arquivo j√° existe na pasta antes de fazer o download\n",
    "def fileExistis():\n",
    "    csvFile = makeFolderName(SOURCE_FOLDER, DF_FILE_NAME, CSV)\n",
    "    parquetFile = makeFolderName(SOURCE_FOLDER, DF_FILE_NAME, PARQUET)\n",
    "\n",
    "    file_path = Path(csvFile)\n",
    "    if not file_path.exists():\n",
    "        print(\"Start downloading fileName: {}.csv\".format(DF_FILE_NAME))\n",
    "        url = \"https://drive.google.com/uc?export=download&id=1Vumu8jo3P3umuUtBZb6mn7YoVIo4X0ON\"\n",
    "        gd.download(url, csvFile, quiet=False)\n",
    "        print(\"Finished download fileName: {}\".format(DF_FILE_NAME))\n",
    "        # convers√£o do dataFrame do formato csv para parquet para reduzir o tamanho do arquivo\n",
    "        originalData = pd.read_csv(csvFile)\n",
    "        print(\"Start parquetFile converter: {}\".format(DF_FILE_NAME))\n",
    "        originalData.to_parquet(parquetFile, engine=\"pyarrow\", index=False)\n",
    "        print(\"Finished parquetFile converter: {}\".format(DF_FILE_NAME))\n",
    "    else:\n",
    "        # convers√£o do dataFrame do formato csv para parquet para reduzir o tamanho do arquivo\n",
    "        print(\"Start load file {}.csv\".format(DF_FILE_NAME))\n",
    "        originalData = pd.read_csv(csvFile)\n",
    "        print(\"Finished load file {}.csv\".format(DF_FILE_NAME))\n",
    "        print(\"Start parquetFile converter: {}.parquet\".format(DF_FILE_NAME))\n",
    "        originalData.to_parquet(parquetFile, engine=\"pyarrow\", index=False)\n",
    "        print(\"Finished parquetFile converter: {}.parquet\".format(DF_FILE_NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FASE 2 - INGEST√ÉO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar a pasta pouso para receber os dados\n",
    "criar_pasta(SOURCE_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start downloading fileName: df_fraud_credit.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?export=download&id=1Vumu8jo3P3umuUtBZb6mn7YoVIo4X0ON\n",
      "From (redirected): https://drive.google.com/uc?export=download&id=1Vumu8jo3P3umuUtBZb6mn7YoVIo4X0ON&confirm=t&uuid=f0fb2e73-b039-4224-87de-7dce421eb63d\n",
      "To: c:\\PROJETOS\\NOTEBOOK\\pipeline\\source\\df_fraud_credit.csv\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.55G/1.55G [03:34<00:00, 7.23MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished download fileName: df_fraud_credit\n",
      "Start parquetFile converter: df_fraud_credit\n",
      "Finished parquetFile converter: df_fraud_credit\n"
     ]
    }
   ],
   "source": [
    "# download dos dados da origem\n",
    "fileExistis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregando o dataFrame a partir do arquivo no formato parquet\n",
    "parquetFile = makeFolderName(SOURCE_FOLDER, DF_FILE_NAME, PARQUET)\n",
    "initialData = pd.read_parquet(parquetFile, engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FASE 3 - TRATAMENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realizar filtro das ocorr√™ncias onde as regi√µes aparencem != 0\n",
    "zeroFilter = initialData.location_region != \"0\"\n",
    "filterData = initialData.loc[zeroFilter]\n",
    "\n",
    "# realizar filtro das ocorr√™ncias de risk_score != none\n",
    "noneRiskScoreFilter = filterData.risk_score != \"none\"\n",
    "filterData = filterData.loc[noneRiskScoreFilter]\n",
    "\n",
    "# realizar filtro das ocorrencias com amount != none\n",
    "noneAmountFilter = filterData.amount != \"none\"\n",
    "filterData = filterData.loc[noneAmountFilter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FASE 4 - CONVERS√ÉO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforma√ß√£o da coluna timestamp em dateTime\n",
    "filterData[\"timestamp\"] = pd.to_datetime(filterData[\"timestamp\"], unit=\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformar risk_score em numerico\n",
    "filterData[\"risk_score\"] = pd.to_numeric(filterData[\"risk_score\"].round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converter todos os dados da coluna amount para o formato Float64\n",
    "filterData[\"amount\"] = filterData[\"amount\"].values.astype(\"float64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FASE 5 - AGREGA√á√ÉO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "riskScoreTable = (\n",
    "    filterData.groupby(\"location_region\")[\"risk_score\"]\n",
    "    .mean()\n",
    "    .round(3)\n",
    "    .reset_index()\n",
    "    .sort_values(by=\"risk_score\", ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesData = filterData[filterData[\"transaction_type\"] == \"sale\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "recentTransactions = salesData.sort_values(\n",
    "    by=[\"receiving_address\", \"timestamp\"], ascending=[True, False]\n",
    ")\n",
    "recentTransactions = recentTransactions.drop_duplicates(subset=[\"receiving_address\"], keep=\"first\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "topRecentTransactions = recentTransactions.nlargest(3, \"amount\")[\n",
    "    [\"receiving_address\", \"amount\", \"timestamp\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FASE 6 - REPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìå **Region by Average Risk **\n",
      "\n",
      "+-----------------+------------+\n",
      "| location_region | risk_score |\n",
      "+-----------------+------------+\n",
      "|  North America  |   45.155   |\n",
      "|  South America  |   45.139   |\n",
      "|      Asia       |   44.995   |\n",
      "|     Africa      |   44.902   |\n",
      "|     Europe      |   44.599   |\n",
      "+-----------------+------------+\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüìå **Region by Average Risk **\\n\")\n",
    "print(tabulate(riskScoreTable, headers=\"keys\", tablefmt=\"pretty\", showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìå **Top 3 'Receiving Address' with the highest 'Amount'**\n",
      "\n",
      "+--------------------------------------------+---------+---------------------+\n",
      "|             receiving_address              | amount  |      timestamp      |\n",
      "+--------------------------------------------+---------+---------------------+\n",
      "| 0x841342e50c508ec4ffdef9b5208719c1dbed7968 | 76568.0 | 2024-01-02 03:53:01 |\n",
      "| 0xe8aacdea4f2d7658e711de611bad8e3b5d6b2c7b | 76563.0 | 2024-01-01 02:49:56 |\n",
      "| 0x231dd8e2959e878a59a26ebdbf6f7d122403f350 | 76559.0 | 2024-01-02 06:31:09 |\n",
      "+--------------------------------------------+---------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüìå **Top 3 'Receiving Address' with the highest 'Amount'**\\n\")\n",
    "print(tabulate(topRecentTransactions, headers=\"keys\", tablefmt=\"pretty\", showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìå **Data Quality Report**\n",
      "\n",
      "üìä Total de registros importados: 9291894\n",
      "‚úÖ Registros v√°lidos: 9142488\n",
      "‚ùå Registros com erro: 149406\n",
      "% Registros com erro: 0.02%\n"
     ]
    }
   ],
   "source": [
    "montar_estatisticas_dataFrame(initialData, filterData)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
